# src/config/config.yaml

# Basic System Configuration
model_name: "meta-llama/Llama-3.2-3B"
data_dir: "data/" # General data directory

# ---- MODIFICATION START ----
# Dataset Specific Paths
hotpotqa_dataset_path: "data/hotpot_dev_distractor_v1.json"
drop_dataset_path: "data/drop_dataset_dev.json"

# Rule Files (Consider making these dataset-specific)
# rules_file: "rules.json" # This can be a generic fallback or removed if using specific ones
hotpotqa_rules_file: "data/rules_hotpotqa.json" # Example, if you rename your current rules.json
drop_rules_file: "data/rules_drop.json"         # You'll need to create this file for DROP rules
# ---- MODIFICATION END ----

knowledge_base: "small_knowledge_base.txt"

# Dimension Management and Embedding Configuration
embeddings:
  symbolic_dim: 384
  neural_dim: 768
  target_dim: 768
  model_name: "all-MiniLM-L6-v2"

# Alignment Configuration
alignment:
  target_dim: 768
  num_heads: 4
  dropout: 0.1
  sym_dim: 384
  neural_dim: 768

# Basic resource thresholds (can be overridden by resource_config.yaml)
resource_thresholds:
  cpu:
    base_threshold: 0.85
    adjustment_factor: 0.08
  memory:
    base_threshold: 0.85
    adjustment_factor: 0.08
  gpu:
    base_threshold: 0.95
    adjustment_factor: 0.05


# Chunking Configuration
chunking:
  chunk_size: 512
  chunk_overlap: 128
  min_chunk_size: 64
  fallback_enabled: true

# Error Recovery Configuration
error_recovery:
  max_retries: 3
  backoff_factor: 1.5
  fallback_enabled: true
  cache_ttl: 3600

# Metrics Configuration
metrics:
  detailed_logging: true
  save_frequency: 100
  history_window: 1000
  performance_tracking: true