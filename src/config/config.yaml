# config.yaml
model_name: "meta-llama/Llama-3.2-3B"
data_dir: "data/"
rules_file: "rules.json"
knowledge_base: "small_knowledge_base.txt"


alignment:
  target_dim: 768
  num_heads: 4
  dropout: 0.1
  sym_dim: 384
  neural_dim: 768


embeddings:
  symbolic_dim: 384
  neural_dim: 384
  target_dim: 768
  model_name: "all-MiniLM-L6-v2"


resource_thresholds:
  cpu:
    base_threshold: 0.85
    adjustment_factor: 0.08
  memory:
    base_threshold: 0.85
    adjustment_factor: 0.08
  gpu:
    base_threshold: 0.95
    adjustment_factor: 0.05
